

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Sample Statistics &#8212; SIMLES: Statistical Inference and Machine Learning for Earth Sciences</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/Module01/M01_N04_SampleStatistics';</script>
    <link rel="canonical" href="https://cdds-uiuc.github.io/simles-book/content/Module01/M01_N04_SampleStatistics.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Estimators" href="../Module02/M02_N01_Estimation.html" />
    <link rel="prev" title="Moments" href="M01_N03_Moments.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/CDDS_logo.png" class="logo__image only-light" alt="SIMLES: Statistical Inference and Machine Learning for Earth Sciences - Home"/>
    <script>document.write(`<img src="../../_static/CDDS_logo.png" class="logo__image only-dark" alt="SIMLES: Statistical Inference and Machine Learning for Earth Sciences - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    SIMLES
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Programming.html">Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">1. Probability Models</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="M01_N01_Probability_Recap.html">Basics of probabilities</a></li>




<li class="toctree-l1"><a class="reference internal" href="M01_N02_Random_Variables.html">Random Variables</a></li>



<li class="toctree-l1"><a class="reference internal" href="M01_Lab1.html">Lab 1.1</a></li>



<li class="toctree-l1"><a class="reference internal" href="M01_N03_Moments.html">Moments</a></li>




<li class="toctree-l1 current active"><a class="current reference internal" href="#">Sample Statistics</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">2. Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Module02/M02_N01_Estimation.html">Estimators</a></li>




<li class="toctree-l1"><a class="reference internal" href="../Module02/M02_N02_Cookbook_Gutenberg-Richter_Law.html">Cookbook: MLE for Gutenberg-Richter Law</a></li>





<li class="toctree-l1"><a class="reference internal" href="../Module02/M02_N03_Cookbook_Precipitation_Return_Times.html">Cookbook: Precipitation return times for Hurricane Harvey</a></li>



<li class="toctree-l1"><a class="reference internal" href="../Module02/M02_Lab2-1.html">Lab 2.1</a></li>



</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/cdds-uiuc/simles-book/master?urlpath=lab/tree/content/Module01/M01_N04_SampleStatistics.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/cdds-uiuc/simles-book/blob/master/content/Module01/M01_N04_SampleStatistics.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/cdds-uiuc/simles-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/cdds-uiuc/simles-book/issues/new?title=Issue%20on%20page%20%2Fcontent/Module01/M01_N04_SampleStatistics.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/Module01/M01_N04_SampleStatistics.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Sample Statistics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Sample Statistics</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-mean-and-the-law-of-large-numbers">Sample Mean and the Law of Large Numbers</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimators">Estimators</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#consistency-of-sample-mean">Consistency of sample mean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unbiasedness-of-sample-mean">Unbiasedness of Sample Mean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise.</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-variance-standard-deviation">Sample Variance / Standard Deviation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#consistency">Consistency</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biased-estimators-of-sample-variance">Biased estimators of sample variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Exercise:</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distribution-the-central-limit-theorem">Sampling Distribution &amp; the central limit theorem</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Exercise:</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#the-extreme-value-theorem">The extreme value theorem</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exponential-distribution">Exponential distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uniform-distribution">Uniform distribution</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-covariance-and-correlation">Sample Covariance and Correlation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pearson-correlation-coefficeient">Pearson Correlation Coefficeient</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spurious-correlation">Spurious Correlation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Exercise</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sample-statistics">
<h1>Sample Statistics<a class="headerlink" href="#sample-statistics" title="Permalink to this heading">#</a></h1>
<p>“Climate is what you expect. Weather is what you get”</p>
<p>“The process mean is what you expect. The sample mean is what you get”</p>
<p>Reading:
<em><strong>Emile-Geay Chapter 4.I and 4.II (p51-58)</strong></em></p>
<p>Other readings:</p>
<p><em><a class="reference external" href="https://en.wikipedia.org/wiki/Sampling_distribution">https://en.wikipedia.org/wiki/Sampling_distribution</a></em></p>
<p><em><a class="reference external" href="https://en.wikipedia.org/wiki/Central_limit_theorem">https://en.wikipedia.org/wiki/Central_limit_theorem</a></em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># These are some parameters to make figures nice (and big)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span><span class="mi">8</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;text.usetex&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">:</span> <span class="s1">&#39;x-large&#39;</span><span class="p">,</span>
          <span class="s1">&#39;figure.figsize&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
         <span class="s1">&#39;axes.labelsize&#39;</span><span class="p">:</span> <span class="s1">&#39;x-large&#39;</span><span class="p">,</span>
         <span class="s1">&#39;axes.titlesize&#39;</span><span class="p">:</span><span class="s1">&#39;x-large&#39;</span><span class="p">,</span>
         <span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">:</span><span class="s1">&#39;x-large&#39;</span><span class="p">,</span>
         <span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">:</span><span class="s1">&#39;x-large&#39;</span><span class="p">}</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="sample-mean-and-the-law-of-large-numbers">
<h1>Sample Mean and the Law of Large Numbers<a class="headerlink" href="#sample-mean-and-the-law-of-large-numbers" title="Permalink to this heading">#</a></h1>
<p>Consider a gaussian process. Let’s say this process has true mean <span class="math notranslate nohighlight">\(\mu\)</span> and true variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. When we work with random samples in python (or any programming language), the process mean and process variance are the values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> we pass to the method that generates random samples such as
<code>stats.norm.rvs(loc=mu,scale=sigma, size=Ndraws)</code></p>
<p>We denote a random variable with a Normal/Gaussian distribution with location/mean <span class="math notranslate nohighlight">\(\mu\)</span> and scale/variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> as</p>
<div class="math notranslate nohighlight">
\[ X\sim\mathcal{N}(\mu,\sigma^2)\]</div>
<p>If we only have a sample of this random variable we can estimate the mean using the <strong>sample mean</strong>:</p>
<div class="math notranslate nohighlight">
\[\overline{X}_n=\frac{1}{n}\sum_{i=1}^n X_i\]</div>
<p>The law of large numbers tells us that the sample mean converges to the process mean for a large enough sample.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Law_of_large_numbers">https://en.wikipedia.org/wiki/Law_of_large_numbers</a></p>
<div class="math notranslate nohighlight">
\[ \overline{X}_n \rightarrow \mu \]</div>
<section id="estimators">
<h2>Estimators<a class="headerlink" href="#estimators" title="Permalink to this heading">#</a></h2>
<p>An estimator is a function (rule) for calculating an estimate of a given quantity based on observed data. <a class="reference external" href="https://en.wikipedia.org/wiki/Estimator">Wikipedia article</a></p>
<p>For example, given some data from a process, we can estimate the mean of process using the sample mean. In this case, the sample mean is an <em>estimator</em> of the process mean.</p>
</section>
<section id="consistency-of-sample-mean">
<h2>Consistency of sample mean<a class="headerlink" href="#consistency-of-sample-mean" title="Permalink to this heading">#</a></h2>
<p>An estimator is consistent if it asymptotes to the process value <em>as the size of the value increases</em>. For the mean,  that statement of consistency is precisely the law of large numbers:</p>
<div class="math notranslate nohighlight">
\[\overline{X}_n \rightarrow \mu  \text{ as } n\rightarrow \infty\]</div>
<p>Let’s convince ourself of the consistence of sample mean with some numerics:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Consistency </span>
<span class="n">mu</span><span class="o">=</span><span class="mf">0.2</span><span class="p">;</span>
<span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span>
<span class="n">sample_size_max</span><span class="o">=</span><span class="mi">10000</span>

<span class="c1">#preallocate vector of sample sizes</span>
<span class="n">sample_mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">sample_size_max</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">X_norm</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">sample_size_max</span><span class="p">)</span>

<span class="c1"># let&#39;s compute the sample mean as a function of sample size (or number of draws)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">sample_size_max</span><span class="p">):</span>
    <span class="n">sample_mean</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sample_mean</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;sample mean&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">sample_size_max</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;process mean&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;n&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x1370f7a10&gt;
</pre></div>
</div>
<img alt="../../_images/3816faf3173d67338851faad87641885fb38e115df4be5095a89702c0e215d36.png" src="../../_images/3816faf3173d67338851faad87641885fb38e115df4be5095a89702c0e215d36.png" />
</div>
</div>
</section>
<section id="unbiasedness-of-sample-mean">
<h2>Unbiasedness of Sample Mean<a class="headerlink" href="#unbiasedness-of-sample-mean" title="Permalink to this heading">#</a></h2>
<p>An estimator is unbiased if its expectation is the same as the process value.</p>
<div class="math notranslate nohighlight">
\[E(\overline{X}_n)=E(X)=\mu\]</div>
<p>While the consistency and unbiasedness look similar, they are actually different. The sample mean is itself a random variable, as it is the sum of <span class="math notranslate nohighlight">\(n\)</span> random variables. Thus, it will have a distribution and it will have a mean - or expected - value.</p>
<p>Here is one way to think about this. Say we are taking daily measurements of a quantity in the lab. We want to measure a true quantity, but we can only do so with some error. Let’s say those errors are normally distributed, and we can model our measurement as:</p>
<div class="math notranslate nohighlight">
\[X=\mu +\varepsilon\]</div>
<p>where <span class="math notranslate nohighlight">\(\varepsilon\)</span> are random errors with zero-mean and variance <span class="math notranslate nohighlight">\(\sigma\)</span>. In this case oure measurement <span class="math notranslate nohighlight">\(X\)</span> is a random variable whose process mean is the true value of the quantity we are after.</p>
<p>Let’s say we take a sample of size <span class="math notranslate nohighlight">\(n\)</span> of that process. Consistency tells us that as the sample mean gets <em>larger</em>, i.e., as we take more independent measurements and average them together, we would approach the true mean. The bias tell us what would happen if we repeat the measurement. Say, we take another sample mean of size <span class="math notranslate nohighlight">\(n\)</span> tomorrow, and another the day after, and so on. Would the mean of all of those sample means also approach the true mean? Yes, if the estimator is also unbiased.</p>
<p>In practice, we may not be able to either take an infinitely large sample, or repeate the measurement. It’s possible that all we have is a sample of size n. We would like to know whether that sample is an unbiased estimate.</p>
<p>For the sample mean, this is easy to prove. Since the sample mean is a random variable, we can also apply the law of large numbers to it: Expectation of the sample mean would actually be the average of an infinite number of sample means.</p>
<div class="math notranslate nohighlight">
\[E(\overline{X}_n)=\lim_{k\rightarrow \infty} \frac{1}{k}\sum_{j=1}^k (\overline X_n)_j\]</div>
<p>A simple re-ordering of the sums shows us that the sample mean is an unbiased estimator:</p>
<div class="math notranslate nohighlight">
\[E(\overline{X}_n)=\lim_{k\rightarrow \infty} \frac{1}{k}\frac{1}{n}\sum_{j=1}^k\sum_{i=1}^n X_{i,j}\]</div>
<div class="math notranslate nohighlight">
\[E(\overline{X}_n)=\frac{1}{n}\sum_{j=1}^n\left[\lim_{k\rightarrow \infty} \frac{1}{k}\sum_{i=1}^k X_{i,j}\right]\]</div>
<p>By the law of large numbers,</p>
<div class="math notranslate nohighlight">
\[E(\overline{X}_n)=\frac{1}{n}\sum_{j=1}^n n\mu=\mu\]</div>
<p>We will assume that we have multiple samples/batches, each with multiple draw/outcomes/measurements of a random variable. Each sample will have the same size, and we will take the sample mean for each of them. Since we don’t have an infinite number of draws, the sample mean will be noisy - it will not be exactly equal to the true process mean. But will the distribution of these sample means be centered around the process mean?</p>
</section>
<section id="exercise">
<h2>Exercise.<a class="headerlink" href="#exercise" title="Permalink to this heading">#</a></h2>
<p>In the cell below, change the number of samples to convince yourself that the expected value of the sample mean converges to the process mean:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Unbiasedness</span>
<span class="n">mu</span><span class="o">=</span><span class="mi">3</span><span class="p">;</span>
<span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">;</span>

<span class="c1"># sample size and number of samples</span>
<span class="n">sample_size</span><span class="o">=</span><span class="mi">20</span>
<span class="n">nsamples</span><span class="o">=</span><span class="mi">100000</span>


<span class="c1"># preallocate vector of sample means</span>
<span class="n">sample_mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nsamples</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># compute a number nsamples of sample means</span>
<span class="c1"># for each sample, draw sample_size draws and average them to get the sample mean:</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nsamples</span><span class="p">):</span>
    <span class="n">X_norm</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">sample_size</span><span class="p">)</span>
    <span class="n">sample_mean</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">sample_size</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X_norm</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">sample_mean</span><span class="p">,</span><span class="mi">30</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_mean</span><span class="p">),</span><span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">ymax</span><span class="o">=</span><span class="n">nsamples</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span><span class="n">colors</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;expected sample mean&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span><span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">ymax</span><span class="o">=</span><span class="n">nsamples</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span><span class="n">colors</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;process mean&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;sample variance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;sample mean&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;number of realizations&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;distribution of sample mean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;distribution of sample mean&#39;)
</pre></div>
</div>
<img alt="../../_images/0fe645916eb392ddc3308f0d30d0968374ab64e1d26905f83e062b3d85c38eac.png" src="../../_images/0fe645916eb392ddc3308f0d30d0968374ab64e1d26905f83e062b3d85c38eac.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="sample-variance-standard-deviation">
<h1>Sample Variance / Standard Deviation<a class="headerlink" href="#sample-variance-standard-deviation" title="Permalink to this heading">#</a></h1>
<p>Remember, the variance is defined as:</p>
<div class="math notranslate nohighlight">
\[V(X)=E([X-\mu)^2]\]</div>
<p>Just like the sample mean, we can define an estimator for the variance as the sample variance.</p>
<div class="math notranslate nohighlight">
\[s_n^2=\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X}_n)^2\]</div>
<p>Now let’s check consistency and bias for the sample variance</p>
<section id="consistency">
<h2>Consistency<a class="headerlink" href="#consistency" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Consistency</span>
<span class="n">mu</span><span class="o">=</span><span class="mi">10</span><span class="p">;</span>
<span class="n">sigma</span><span class="o">=</span><span class="mi">4</span><span class="p">;</span> <span class="c1">#variance =sigma^2</span>
<span class="n">sample_size_max</span><span class="o">=</span><span class="mi">50000</span>

<span class="c1">#preallocate vector of sample sizes</span>
<span class="n">sample_var</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">sample_size_max</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">X_norm</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">sample_size_max</span><span class="p">)</span>

<span class="c1"># let&#39;s compute the sample variance as a function of sample size (or number of draws)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">sample_size_max</span><span class="p">):</span>
    <span class="n">sample_var</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sample_var</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;sample variance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">xmax</span><span class="o">=</span><span class="n">sample_size_max</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;process variance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;n&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;sample variance&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;sample variance&#39;)
</pre></div>
</div>
<img alt="../../_images/ef861976c7bac0dc69e1709aef401306a5fd24f46c60b4834894f70201af319c.png" src="../../_images/ef861976c7bac0dc69e1709aef401306a5fd24f46c60b4834894f70201af319c.png" />
</div>
</div>
</section>
<section id="biased-estimators-of-sample-variance">
<h2>Biased estimators of sample variance<a class="headerlink" href="#biased-estimators-of-sample-variance" title="Permalink to this heading">#</a></h2>
<p>Let’s now check for the bias of this sample variance estimator. Just like before, we will draw a large number of batches (15,000), each with a samples size of 100. For each of these batches we will compute the sample variance, each based on a sample size of 100.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bias</span>
<span class="n">mu</span><span class="o">=</span><span class="mf">0.4</span><span class="p">;</span>
<span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">;</span> <span class="c1">#variance =sigma^2</span>

<span class="c1"># sample size and number of samples</span>
<span class="n">sample_size</span><span class="o">=</span><span class="mi">100</span>
<span class="n">nsamples</span><span class="o">=</span><span class="mi">15000</span>

<span class="c1"># preallocate vector of sample means</span>
<span class="n">sample_var</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nsamples</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># compute a number nsamples of sample means</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nsamples</span><span class="p">):</span>
    <span class="n">X_norm</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">sample_size</span><span class="p">)</span>
    <span class="n">sample_var</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">sample_size</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">sample_var</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="n">rwidth</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_var</span><span class="p">),</span><span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">ymax</span><span class="o">=</span><span class="n">nsamples</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span><span class="n">colors</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;expected sample variance &#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">ymax</span><span class="o">=</span><span class="n">nsamples</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span><span class="n">colors</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;process variance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;sample variance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;number of realizations&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribution of Sample variance (sample size=100 )&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0, 0.5)
</pre></div>
</div>
<img alt="../../_images/94f056952e443ebc9bb7fd0ce39c1449040add6c5afe66e56a40a35bd3d75c85.png" src="../../_images/94f056952e443ebc9bb7fd0ce39c1449040add6c5afe66e56a40a35bd3d75c85.png" />
</div>
</div>
<p>So, the simple sample standard variance is a <em><strong>consistent, but biased</strong></em> estimator of the process variance. Sure, if the sample is large enough, it will eventually converget. But for finite samples, its expected value is <strong>not</strong> equal to the true value of the process variance.</p>
<p>It turns out that if we want a consistent <em>and</em> unbiased estimator for the variance we have to use a corrected sample variance</p>
<div class="math notranslate nohighlight">
\[s_{n-1}^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X}_n)^2\]</div>
<p>We will show why that is in class.</p>
</section>
<section id="id1">
<h2>Exercise:<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>Show (numerically) that the corrected sample variance is unbiased. Repeat the experiment above by estimating the mean of the distribution of the corrected sample variance, and show that is matches the process variance .</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Exercise Code block</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="sampling-distribution-the-central-limit-theorem">
<h1>Sampling Distribution &amp; the central limit theorem<a class="headerlink" href="#sampling-distribution-the-central-limit-theorem" title="Permalink to this heading">#</a></h1>
<p>Since the sample mean is a random variable, it means it has a distribution. The Central Limit Theorem tells us what that distribution is:</p>
<p><em><strong>Central Limit Theorem:</strong></em>
For a sequence <span class="math notranslate nohighlight">\(\{X_1,\ldots, X_n\}\)</span> of independent and identically distributed random variables with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, if the sample size <span class="math notranslate nohighlight">\(n\)</span> is large enough, the distribution of the sample mean is normal with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2/n\)</span>:</p>
<div class="math notranslate nohighlight">
\[\overline{X}_n=\frac{1}{n}\sum_{i=1}^n X_i \sim \mathcal N(\mu,\sigma^2/n)\]</div>
<p>This is one of the most powerful results in statistics. It tells us how quickly the uncertainty in the mean decreases: in particular, the variance decreases as the number of observations (and that the standard deviation decreases as the square root of the number of observations).</p>
<p><strong>Attention</strong> Notice that the Central Limit Theorem does <strong>not</strong> require the random variables to be normal/gaussian. That’s right, the sample mean of <strong>any</strong> random variable tends to be normal/gaussian for a large enough sample.</p>
<p><img alt="Patrikc" src="https://c.tenor.com/3xoRK7hFE3gAAAAC/patrick-star-spongebob-squarepants.gif" /></p>
<p>The cell below shows a numerical evaluation of the CLT for an exponential distribution. We will be using values of <span class="math notranslate nohighlight">\(n=[1,5,25,200]\)</span> for the sample size over which we take the sample mean.</p>
<ul class="simple">
<li><p>pick a sample size <span class="math notranslate nohighlight">\(n\)</span> - i.e. the number of samples we are averaging over to compute the sample mean.
$<span class="math notranslate nohighlight">\( \overline X_n=\frac{1}{n}\sum_i X_n\)</span>$</p></li>
<li><p>Repeatedly (i.e. <span class="math notranslate nohighlight">\(m=10,000\)</span> times) draw <span class="math notranslate nohighlight">\(n\)</span> samples and take their sample mean.</p></li>
<li><p>Plot the histogram of the <span class="math notranslate nohighlight">\(m=10,000\)</span> sample means.</p></li>
<li><p>Compare this histogram with means with the theoretical pdf of a gaussian/normal distribution given by the Central Limit Theorem, i.e. a gaussian/normal with mean  <span class="math notranslate nohighlight">\(\mu_{clt}=\mu_X\)</span> and variance <span class="math notranslate nohighlight">\(\sigma_{clt}^2=\sigma_X^2/n\)</span> (standard deviation <code>scale</code>=<span class="math notranslate nohighlight">\(\sigma_{clt}=\sigma_X/\sqrt n\)</span>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Answer </span>
<span class="n">m</span><span class="o">=</span><span class="mi">10000</span>
<span class="n">n</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>
<span class="n">Nbins</span><span class="o">=</span><span class="mi">30</span>

<span class="c1"># scale for exponential distribution</span>
<span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span>

<span class="c1"># mean and variance for exponential distribution</span>
<span class="n">mu_x</span><span class="o">=</span><span class="n">scale</span>
<span class="n">sig_x</span><span class="o">=</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>

<span class="c1"># repeat the exericse for four value n.</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="c1"># preallocate vector of sample means</span>
    <span class="n">sample_mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="c1"># compute a number of sample means</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="c1"># draw n[j] draws and average them to get the sample mean:</span>
        <span class="n">X</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
        <span class="n">sample_mean</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        
    
    <span class="c1">#compute the theoretical pdf given by the CLT</span>
    <span class="n">mu_clt</span><span class="o">=</span><span class="n">mu_x</span>
    <span class="n">sig_clt</span><span class="o">=</span><span class="n">sig_x</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    <span class="n">z</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">);</span>
    <span class="n">norm_pdf</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">loc</span><span class="o">=</span><span class="n">mu_clt</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">sig_clt</span><span class="p">);</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">sample_mean</span><span class="p">,</span><span class="n">Nbins</span><span class="p">,</span><span class="n">rwidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sample Mean for n=&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">norm_pdf</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;gaussian pdf&#39;</span><span class="p">);</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">right</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;pdf/histogram&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ba65496ecb933b335d3c00e921550e87183bd4bdea65a95b3982da037a0e768f.png" src="../../_images/ba65496ecb933b335d3c00e921550e87183bd4bdea65a95b3982da037a0e768f.png" />
</div>
</div>
<section id="id2">
<h2>Exercise:<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>Show numerically that the central limit theorem holds for other distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise Block</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="the-extreme-value-theorem">
<h1>The extreme value theorem<a class="headerlink" href="#the-extreme-value-theorem" title="Permalink to this heading">#</a></h1>
<p>The Extreme Value Theorem says if the distribution of block maxima of any distribution converges, than it converges to a GEV distribution.</p>
<p>For a sequence <span class="math notranslate nohighlight">\(\{X_1,\ldots, X_n\}\)</span> of independent and identically distributed random variables, and for large enough <span class="math notranslate nohighlight">\(n\)</span>, if their maximum converges, it converges to a GEV:</p>
<div class="math notranslate nohighlight">
\[\max{\{X_1,\ldots, X_n\}} \sim G(x)\]</div>
<p>For example, we can consider <span class="math notranslate nohighlight">\(X\)</span> to be the amount of daily precipitation that falls in a certain location. If <span class="math notranslate nohighlight">\(n=365\)</span> than <span class="math notranslate nohighlight">\(Y=\max{\{X_1,\ldots, X_n\}}\)</span> is a random variable that describes the rainiest day in a given year.</p>
<p>This is a result that is for a sample maxima, what the Central Limit Theorem is for the sample mean. Note that unlike the CLT, the maxima may not always converge. But if it does converge, than it converges to a GEV.</p>
<p>The power of the GEV, like the power of the CLT, is that you can apply it when you don’t know the underlying distribution. In particular, even if we don’t know the exact distribution of daily precipitation, the CLT tells us that the distribution of annual-mean precipitation should still be normal, and the extreme value theorem tells us that the distribution of annual-max precipitation should be GEV-distributed, allowing us to model these and make predictions of things like flood recurrence times.</p>
<p>The cells below show the behaviour of sample/block maxima for an exponential and a uniform distribution.</p>
<section id="exponential-distribution">
<h2>Exponential distribution<a class="headerlink" href="#exponential-distribution" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">=</span><span class="mi">10000</span>
<span class="n">n</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>
<span class="n">Nbins</span><span class="o">=</span><span class="mi">40</span>
<span class="n">shape</span><span class="o">=</span><span class="mi">1</span>
<span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span>

<span class="n">mu_x</span><span class="o">=</span><span class="n">scale</span>
<span class="n">sig_x</span><span class="o">=</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="c1"># preallocate vector of sample means</span>
    <span class="n">sample_max</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">X</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
        <span class="n">sample_max</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># compute a number nsamples of sample means</span>
    <span class="c1"># for each sample, draw sample_size draws and average them to get the sample mean:</span>
   
    <span class="n">z</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10000</span><span class="p">);</span>
    
    <span class="c1"># fit a GEV to the data. We will talk more about fitting distributions in the next module.</span>
    <span class="n">c</span><span class="p">,</span><span class="n">loc_gev</span><span class="p">,</span><span class="n">scale_gev</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">genextreme</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sample_max</span><span class="p">)</span>
    
    <span class="n">gev_pdf</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">genextreme</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">loc</span><span class="o">=</span><span class="n">loc_gev</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">scale_gev</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">sample_max</span><span class="p">,</span><span class="n">Nbins</span><span class="p">,</span><span class="n">rwidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sample Max for n=&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">gev_pdf</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;GEV&#39;</span><span class="p">);</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/849296f392fb1a9416f47fbb464276ab37e0a4414a0bbf9dcf89482760bb88f3.png" src="../../_images/849296f392fb1a9416f47fbb464276ab37e0a4414a0bbf9dcf89482760bb88f3.png" />
</div>
</div>
</section>
<section id="uniform-distribution">
<h2>Uniform distribution<a class="headerlink" href="#uniform-distribution" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uniform Distribution </span>
<span class="n">m</span><span class="o">=</span><span class="mi">10000</span>
<span class="n">n</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>
<span class="n">Nbins</span><span class="o">=</span><span class="mi">40</span>

<span class="n">scale</span><span class="o">=</span><span class="mi">1000</span><span class="p">;</span>

<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="c1"># preallocate vector of sample means</span>
    <span class="n">sample_max</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">X</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
        <span class="n">sample_max</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># compute a number nsamples of sample means</span>
    <span class="c1"># for each sample, draw sample_size draws and average them to get the sample mean:</span>
   
    <span class="n">z</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1000</span><span class="p">,</span><span class="mi">10000</span><span class="p">);</span>
    

    <span class="n">c</span><span class="p">,</span><span class="n">loc_gev</span><span class="p">,</span><span class="n">scale_gev</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">genextreme</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sample_max</span><span class="p">)</span>    
    <span class="n">gev_pdf</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">genextreme</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">loc</span><span class="o">=</span><span class="n">loc_gev</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">scale_gev</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">sample_max</span><span class="p">,</span><span class="n">Nbins</span><span class="p">,</span><span class="n">rwidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sample Max for n=&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">gev_pdf</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;GEV&#39;</span><span class="p">);</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05c39896307f6e361ea0b3f7d7a99e0ef4433a097b7c84b6c9265e2fe10a0a04.png" src="../../_images/05c39896307f6e361ea0b3f7d7a99e0ef4433a097b7c84b6c9265e2fe10a0a04.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="sample-covariance-and-correlation">
<h1>Sample Covariance and Correlation<a class="headerlink" href="#sample-covariance-and-correlation" title="Permalink to this heading">#</a></h1>
<section id="pearson-correlation-coefficeient">
<h2>Pearson Correlation Coefficeient<a class="headerlink" href="#pearson-correlation-coefficeient" title="Permalink to this heading">#</a></h2>
<p>Just like for variance, we can estimate sample covariance and sample correlation.
Most commonly, we will estimate sample correlation, using the <a class="reference external" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation Coefficient</a> <span class="math notranslate nohighlight">\(\rho\)</span>.</p>
<div class="math notranslate nohighlight">
\[ \rho=\frac{\frac{1}{n-1}\sum\left(x_{i}y_{i}-\overline{x}\overline{y}\right)}{s_{x}s_{Y}}\]</div>
<p>where <span class="math notranslate nohighlight">\(s_{x}\)</span> is the bias corrected sample variance:</p>
<div class="math notranslate nohighlight">
\[ s_{x}=\sqrt{\frac{1}{n-1}\sum\left(x_{i}^{2}-\overline{x}\right)}\]</div>
<p>The cell below draws sample_size outcomes from multivariate normal distribution with true process <span class="math notranslate nohighlight">\(\rho=0.8\)</span>. It then use the sample <span class="math notranslate nohighlight">\(\rho\)</span> to estimate the correlation coefficient.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_size</span><span class="o">=</span><span class="mi">100</span>
<span class="n">mu_x</span><span class="o">=</span><span class="mi">1</span>     <span class="c1"># mean of X</span>
<span class="n">mu_y</span><span class="o">=</span><span class="mi">0</span>     <span class="c1"># mean of Y</span>
<span class="n">var_X</span><span class="o">=</span><span class="mi">1</span>    <span class="c1"># Variance of X</span>
<span class="n">var_Y</span><span class="o">=</span><span class="mi">2</span>    <span class="c1"># variance of Y</span>
<span class="n">rho</span><span class="o">=</span><span class="mf">0.8</span>  <span class="c1"># Correlation coefficient</span>
        
<span class="c1"># make a covariance matrix</span>
<span class="n">mu_vec</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_x</span><span class="p">,</span><span class="n">mu_y</span><span class="p">])</span>
<span class="n">cov_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">var_X</span><span class="p">,</span> <span class="n">rho</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_X</span><span class="o">*</span><span class="n">var_Y</span><span class="p">)],</span> <span class="p">[</span><span class="n">rho</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_X</span><span class="o">*</span><span class="n">var_Y</span><span class="p">),</span> <span class="n">var_Y</span><span class="p">]])</span>
<span class="n">Xvec</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">cov</span> <span class="o">=</span> <span class="n">cov_mat</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">mu_vec</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">sample_size</span><span class="p">)</span>    
<span class="n">x</span><span class="o">=</span><span class="n">Xvec</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y</span><span class="o">=</span><span class="n">Xvec</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>


<span class="n">sample_rho</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sample size=&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; process r =&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">rho</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; sample r = &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">sample_rho</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x15c272720&gt;]
</pre></div>
</div>
<img alt="../../_images/ae777d6598ab9202c71a15ceac0cd4e22352c4993fb5ccb589fda08f6bd29fb6.png" src="../../_images/ae777d6598ab9202c71a15ceac0cd4e22352c4993fb5ccb589fda08f6bd29fb6.png" />
</div>
</div>
</section>
<section id="spurious-correlation">
<h2>Spurious Correlation<a class="headerlink" href="#spurious-correlation" title="Permalink to this heading">#</a></h2>
<p>Correlation coefficents are noisy. You can get a non-zero correlation even the true process correlation is zero. That is, given two independent random variables, if we only have a small sample size from them and compute the sample correlation, it will likely be non-zero. Only when we have a very large number of samples does the sample correlation converge to zero.  This is the basis of many many many spurious results in science, especially in social sciences.</p>
<p>In the code below we look at the distribution of the sample correlation coefficient for a small sample. We draw from two independent random variables (true process correlation is zero), and we plot the distribution of sample correlation. It is centered around zero, but notice that even for a decent sample size (e.g. 50) we can still get correlations of 0.4 when in fact the variables are independent. Later on, this observation will be the basis of hypothesis testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#parameters</span>

<span class="c1"># sample size and number of samples</span>
<span class="n">sample_size</span><span class="o">=</span><span class="mi">50</span>
<span class="n">nsamples</span><span class="o">=</span><span class="mi">10000</span>

<span class="n">mu_x</span><span class="o">=</span><span class="mi">1</span>     <span class="c1"># mean of X</span>
<span class="n">mu_y</span><span class="o">=</span><span class="mi">0</span>     <span class="c1"># mean of Y</span>
<span class="n">var_X</span><span class="o">=</span><span class="mi">1</span>    <span class="c1"># Variance of X</span>
<span class="n">var_Y</span><span class="o">=</span><span class="mi">2</span>    <span class="c1"># variance of Y</span>
<span class="n">rho</span><span class="o">=</span><span class="mi">0</span>  <span class="c1"># Correlation coefficient</span>
        
<span class="c1"># make a covariance matrix</span>
<span class="n">mu_vec</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_x</span><span class="p">,</span><span class="n">mu_y</span><span class="p">])</span>
<span class="n">cov_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">var_X</span><span class="p">,</span> <span class="n">rho</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_X</span><span class="o">*</span><span class="n">var_Y</span><span class="p">)],</span> <span class="p">[</span><span class="n">rho</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_X</span><span class="o">*</span><span class="n">var_Y</span><span class="p">),</span> <span class="n">var_Y</span><span class="p">]])</span>

<span class="c1"># preallocate vector of sample rhos</span>
<span class="n">sample_rho</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nsamples</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># compute a number nsamples of correlation</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nsamples</span><span class="p">):</span>
    <span class="n">Xvec</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">cov</span> <span class="o">=</span> <span class="n">cov_mat</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">mu_vec</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">sample_size</span><span class="p">)</span>    
    <span class="n">x</span><span class="o">=</span><span class="n">Xvec</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y</span><span class="o">=</span><span class="n">Xvec</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">rho</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">sample_rho</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">=</span><span class="n">rho</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">sample_rho</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">rwidth</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([5.43720783e-03, 1.08744157e-02, 1.35930196e-02, 3.80604548e-02,
        9.78697409e-02, 1.87583670e-01, 4.21383607e-01, 5.98092861e-01,
        9.13450915e-01, 1.19618572e+00, 1.59853910e+00, 2.16400872e+00,
        2.38965284e+00, 2.77841320e+00, 2.81103645e+00, 2.54461326e+00,
        2.35159239e+00, 1.94108319e+00, 1.74262511e+00, 1.30764848e+00,
        8.75390460e-01, 5.68188218e-01, 2.82734807e-01, 1.71272047e-01,
        1.08744157e-01, 4.34976626e-02, 1.63116235e-02, 2.71860391e-03,
        2.71860391e-03, 2.71860391e-03]),
 array([-0.52942613, -0.49264254, -0.45585896, -0.41907537, -0.38229179,
        -0.3455082 , -0.30872461, -0.27194103, -0.23515744, -0.19837386,
        -0.16159027, -0.12480669, -0.0880231 , -0.05123952, -0.01445593,
         0.02232766,  0.05911124,  0.09589483,  0.13267841,  0.169462  ,
         0.20624558,  0.24302917,  0.27981276,  0.31659634,  0.35337993,
         0.39016351,  0.4269471 ,  0.46373068,  0.50051427,  0.53729786,
         0.57408144]),
 &lt;BarContainer object of 30 artists&gt;)
</pre></div>
</div>
<img alt="../../_images/99b68f282e597ee3ed56ebf61b2315deeb81dc86a6e9f7874470455fe49db98d.png" src="../../_images/99b68f282e597ee3ed56ebf61b2315deeb81dc86a6e9f7874470455fe49db98d.png" />
</div>
</div>
</section>
<section id="id3">
<h2>Exercise<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Redo the scatter plot above (two code blocks above). Set the correlation to zero and, for different sample sizes, draw samples from the distribution.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/Module01"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="M01_N03_Moments.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Moments</p>
      </div>
    </a>
    <a class="right-next"
       href="../Module02/M02_N01_Estimation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Estimators</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Sample Statistics</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-mean-and-the-law-of-large-numbers">Sample Mean and the Law of Large Numbers</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimators">Estimators</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#consistency-of-sample-mean">Consistency of sample mean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unbiasedness-of-sample-mean">Unbiasedness of Sample Mean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise.</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-variance-standard-deviation">Sample Variance / Standard Deviation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#consistency">Consistency</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biased-estimators-of-sample-variance">Biased estimators of sample variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Exercise:</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distribution-the-central-limit-theorem">Sampling Distribution &amp; the central limit theorem</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Exercise:</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#the-extreme-value-theorem">The extreme value theorem</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exponential-distribution">Exponential distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uniform-distribution">Uniform distribution</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-covariance-and-correlation">Sample Covariance and Correlation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pearson-correlation-coefficeient">Pearson Correlation Coefficeient</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spurious-correlation">Spurious Correlation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Exercise</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cristian Proistosescu
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>